{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e5753f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from simd_r_drive_ws_client import DataStoreWsClient\n",
    "import simd_r_drive_ws_client\n",
    "\n",
    "# simd_r_drive_ws_client.setup_logging(logging.info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26e40a2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "thread '<unnamed>' panicked at /Users/runner/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/muxio-tokio-rpc-client-0.6.0-alpha/src/rpc_client.rs:17:14:\n",
      "Failed to connect: Io(Os { code: 61, kind: ConnectionRefused, message: \"Connection refused\" })\n",
      "note: run with `RUST_BACKTRACE=1` environment variable to display a backtrace\n"
     ]
    },
    {
     "ename": "PanicException",
     "evalue": "Failed to connect: Io(Os { code: 61, kind: ConnectionRefused, message: \"Connection refused\" })",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mPanicException\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m client = \u001b[43mDataStoreWsClient\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m127.0.0.1:8081\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# client = DataStoreWsClient(\"192.168.0.10:3000\")\u001b[39;00m\n",
      "\u001b[31mPanicException\u001b[39m: Failed to connect: Io(Os { code: 61, kind: ConnectionRefused, message: \"Connection refused\" })"
     ]
    }
   ],
   "source": [
    "client = DataStoreWsClient(\"127.0.0.1:8081\")\n",
    "# client = DataStoreWsClient(\"192.168.0.10:3000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861128de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from typing import Dict, List, Union, Any, Optional, Tuple\n",
    "\n",
    "\n",
    "# # --- Structured Helper Functions ---\n",
    "\n",
    "# Note: This was moved to the client\n",
    "# def batch_read_structured(\n",
    "#     client: DataStoreWsClient,\n",
    "#     data: Union[Dict[Any, bytes], List[Dict[Any, bytes]]]\n",
    "# ) -> Union[Dict[Any, Optional[bytes]], List[Dict[Any, Optional[bytes]]]]:\n",
    "#     \"\"\"\n",
    "#     Takes a dict or list of dicts, where values are datastore keys. It fetches\n",
    "#     all keys using a single high-performance batch call and returns a new object\n",
    "#     with the same shape, with values replaced by the fetched data.\n",
    "\n",
    "#     :param client: An instance of the DataStoreWsClient.\n",
    "#     :param data: The dict or list of dicts to process.\n",
    "#     :return: A new object with the same shape, with values replaced by fetched data.\n",
    "#     \"\"\"\n",
    "#     is_single_dict = isinstance(data, dict)\n",
    "#     dict_list = [data] if is_single_dict else data\n",
    "\n",
    "#     # Step 1: Decompile the structure to get a flat list of all datastore keys,\n",
    "#     # while remembering the original Python keys for later reconstruction.\n",
    "#     keys_to_fetch = []\n",
    "#     original_keys_map = []\n",
    "\n",
    "#     for d in dict_list:\n",
    "#         if not isinstance(d, dict):\n",
    "#             raise TypeError(\"All items in the list must be dictionaries.\")\n",
    "\n",
    "#         original_keys = list(d.keys())\n",
    "#         original_keys_map.append(original_keys)\n",
    "#         keys_to_fetch.extend(d.values())\n",
    "\n",
    "#     # Step 2: Call the simple, fast Rust function with the flat list of keys.\n",
    "#     fetched_results = client.batch_read(keys_to_fetch)\n",
    "\n",
    "#     # Step 3: Rebuild the original structure with the new values.\n",
    "#     results_iterator = iter(fetched_results)\n",
    "#     new_dict_list = []\n",
    "\n",
    "#     for original_keys in original_keys_map:\n",
    "#         new_dict = {}\n",
    "#         for key in original_keys:\n",
    "#             new_dict[key] = next(results_iterator)\n",
    "#         new_dict_list.append(new_dict)\n",
    "\n",
    "#     # If the original input was a single dict, return a single dict.\n",
    "#     return new_dict_list[0] if is_single_dict else new_dict_list\n",
    "\n",
    "\n",
    "# Note: This will probably not be implemented\n",
    "# def batch_write_structured(\n",
    "#     client: DataStoreWsClient,\n",
    "#     data: Union[Dict[bytes, bytes], List[Dict[bytes, bytes]]]\n",
    "# ) -> None:\n",
    "#     \"\"\"\n",
    "#     Takes a dict or list of dicts and writes all key-value pairs to the\n",
    "#     datastore in a single high-performance batch call. The dictionary keys\n",
    "#     are treated as datastore keys and the values as the payload.\n",
    "\n",
    "#     :param client: An instance of the DataStoreWsClient.\n",
    "#     :param data: The dict or list of dicts to write to the store.\n",
    "#     \"\"\"\n",
    "#     is_single_dict = isinstance(data, dict)\n",
    "#     dict_list = [data] if is_single_dict else data\n",
    "\n",
    "#     # Step 1: Decompile the structure into a flat list of (key, payload) tuples.\n",
    "#     entries_to_write = []\n",
    "#     for d in dict_list:\n",
    "#         if not isinstance(d, dict):\n",
    "#             raise TypeError(\"All items in the list must be dictionaries.\")\n",
    "#         # .items() returns a list of (key, value) tuples\n",
    "#         entries_to_write.extend(d.items())\n",
    "\n",
    "#     # Step 2: Call the simple, fast Rust function with the flat list.\n",
    "#     client.batch_write(entries_to_write)\n",
    "\n",
    "\n",
    "# --- USAGE EXAMPLE ---\n",
    "\n",
    "\n",
    "# 1. Create the client instance from your Rust module\n",
    "# client = DataStoreWsClient(\"ws://127.0.0.1:8080\")\n",
    "print(\"-\" * 20)\n",
    "\n",
    "\n",
    "\n",
    "client.batch_write([\n",
    "    (b\"testing1221\", b\"hello there!!!!\"),\n",
    "    (b\"testing1\", b\"12345\"),\n",
    "    (b\"testing2\", b\"12345\"),\n",
    "    (b\"bytes\", bytes(1024)),\n",
    "    (b\"name\", b\"jeremy\")\n",
    "])\n",
    "\n",
    "# display(client.batch_read([\n",
    "#     b\"testing1221\",\n",
    "#     b\"testing1\",\n",
    "# ]))\n",
    "\n",
    "client.batch_read_structured([{\n",
    "    \"my_name\": b\"name\",\n",
    "}, {\n",
    "    \"my_name\": b\"testing2\",\n",
    "}])\n",
    "\n",
    "\n",
    "# 3. Now, prepare a request to read some of that data back.\n",
    "# Here, the dictionary values are the datastore keys we want to fetch.\n",
    "# read_requests = [\n",
    "#     {\n",
    "#         \"profile\": b'user::124',\n",
    "#         \"session\": b'session::xyz'\n",
    "#     },\n",
    "#     {\n",
    "#         \"main_image\": b'product::abc',\n",
    "#         \"missing_item\": b'product::zzz' # This key does not exist\n",
    "#     }\n",
    "# ]\n",
    "\n",
    "# print(\">>> Calling batch_read_structured...\")\n",
    "# hydrated_data = batch_read_structured(client, read_requests)\n",
    "\n",
    "# display(hydrated_data)\n",
    "\n",
    "# # Add assertions to verify the result\n",
    "# expected_hydrated_data = [\n",
    "#     {'profile': b'{\"name\": \"Alice\", \"email\": \"alice@example.com\"}', 'session': b'{\"token\": \"secret_token\", \"ttl\": 3600}'},\n",
    "#     {'main_image': b'FAKE_IMAGE_BYTES', 'missing_item': None}\n",
    "# ]\n",
    "# assert hydrated_data == expected_hydrated_data, f\"Assertion Failed:\\nExpected: {expected_hydrated_data}\\nGot: {hydrated_data}\"\n",
    "# print(\"\\n>>> Assertion for hydrated list passed!\")\n",
    "\n",
    "\n",
    "# print(\"\\n--- Hydrated List ---\")\n",
    "# import json\n",
    "# for item in hydrated_data:\n",
    "#     print(json.dumps(item, indent=2, default=lambda o: o.decode(errors='ignore')))\n",
    "# print(\"-\" * 20)\n",
    "\n",
    "\n",
    "# # 4. Demonstrate with a single dictionary for both write and read.\n",
    "# print(\">>> Calling batch_write_structured with a single dict...\")\n",
    "# single_dict_to_write = {b'config::system': b'{\"theme\": \"dark\"}'}\n",
    "# batch_write_structured(client, single_dict_to_write)\n",
    "\n",
    "# print(\"\\n>>> Calling batch_read_structured with a single dict...\")\n",
    "# single_read_request = {\"system_config\": b'config::system'}\n",
    "# hydrated_single = batch_read_structured(client, single_read_request)\n",
    "\n",
    "# # Add assertion to verify the result\n",
    "# expected_hydrated_single = {'system_config': b'{\"theme\": \"dark\"}'}\n",
    "# assert hydrated_single == expected_hydrated_single, f\"Assertion Failed:\\nExpected: {expected_hydrated_single}\\nGot: {hydrated_single}\"\n",
    "# print(\"\\n>>> Assertion for hydrated dictionary passed!\")\n",
    "\n",
    "\n",
    "# print(\"\\n--- Hydrated Dictionary ---\")\n",
    "# print(json.dumps(hydrated_single, indent=2, default=lambda o: o.decode(errors='ignore')))\n",
    "# print(\"\\nAll tests passed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ff17bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from simd_r_drive_ws_client import DataStoreWsClient\n",
    "import os, secrets, time, sys\n",
    "\n",
    "\n",
    "\n",
    "# â”€â”€ 1.  Prepare a *big* payload  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "#\n",
    "# â€¢ 200 000 keys, each key â‰ˆ 10 bytes  â†’  ~2 MB of key-names\n",
    "# â€¢ 64-byte value per key              â†’  ~12 MB of payload\n",
    "#   (big enough to burst an 8 or 16 MiB frame cap)\n",
    "\n",
    "KEYS     = [f\"key-{i}\".encode() for i in range(900_000)]\n",
    "PAYLOAD  = secrets.token_bytes(64)\n",
    "\n",
    "print(f\"Writing {len(KEYS)} keys â€¦\")\n",
    "start = time.perf_counter()\n",
    "\n",
    "# for k in KEYS:\n",
    "#     c.write(k, PAYLOAD)           # tiny individual writes = no problem\n",
    "client.batch_write(list(zip(KEYS, [PAYLOAD] * len(KEYS))))\n",
    "# print(f\"âœ“ wrote in {time.perf_counter()-start:.1f}s\")\n",
    "\n",
    "# â”€â”€ 2.  Add one missing key so we get a None in the output  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "batch_query = KEYS + [b\"missing-key\"]\n",
    "\n",
    "print(\"\\nIssuing giant batch_read â€¦ (this is expected to blow up)\")\n",
    "try:\n",
    "    _ = client.batch_read(batch_query)     #  â† BOOM (if frame too large)\n",
    "    print(\"â—  Surprisingly succeeded â€“ your frame cap is already high.\")\n",
    "except Exception as e:\n",
    "    print(\"ğŸ’¥  batch_read raised:\", e)\n",
    "    print(\"Most likely the server closed the frame early â†’ decoder saw an \"\n",
    "          \"invalid tag byte and bailed out.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec03abb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbed0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.batch_write([\n",
    "    (b\"testing1221\", b\"hello there!!!!\"),\n",
    "    (b\"testing1\", b\"12345\"),\n",
    "    (b\"testing2\", b\"12345\"),\n",
    "    (b\"bytes\", bytes(1024))\n",
    "])\n",
    "\n",
    "# client.stage_write(b\"hello\", b\"world\")\n",
    "\n",
    "\n",
    "# print(\"reading\")\n",
    "# for i in range(1, 1000):\n",
    "#     print(i)\n",
    "#     client.write(i.to_bytes(4), i.to_bytes(4))\n",
    "\n",
    "#     client.read(i.to_bytes(4))\n",
    "\n",
    "display(client.read(b\"testing1221\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3964779",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.stage_write_flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb83157",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(client.read(b\"bytes\"))\n",
    "client.read(b\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193596fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

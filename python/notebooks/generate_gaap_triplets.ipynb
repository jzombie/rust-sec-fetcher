{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "MIXED ANCHOR GENERATION (Randomized at output time)\n",
    "\n",
    "For each row, we create ONE anchor:\n",
    " - EITHER just the description\n",
    " - OR \"statement_type.lower() description\"\n",
    "\n",
    "No duplication ahead of time, no altered anchor tags.\n",
    "Balance/period logic for negatives is preserved.\n",
    "Subcategories are ignored.\n",
    "\"\"\"\n",
    "\n",
    "import csv\n",
    "import json\n",
    "import random\n",
    "from collections import defaultdict\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# ========== CONFIG ==========\n",
    "INPUT_CSV = \"data/us_gaap_2025_verified_subcategory_path.csv\"\n",
    "OUTPUT_JSONL = \"data/us_gaap_triplet_training_data_filtered.jsonl\"\n",
    "\n",
    "MAX_TRIPLETS = 200000\n",
    "MIN_MARGIN = 0.05\n",
    "\n",
    "POSITIVE_SIM_THRESHOLD = 0.75\n",
    "POSITIVE_ATTEMPTS_PER_ANCHOR = 30\n",
    "NEGATIVE_ATTEMPTS_PER_POSITIVE = 30\n",
    "NEGATIVE_CROSS_STATEMENT_RATIO = 0.5\n",
    "MAX_NEG_MATCHES_PER_POS = 1\n",
    "\n",
    "PARTIAL_SAVE_INTERVAL = 10000\n",
    "NEAR_DUPLICATE_ANCHOR_POS_THRESHOLD = 0.90\n",
    "\n",
    "model = SentenceTransformer(\"BAAI/bge-large-en-v1.5\", device=device)\n",
    "\n",
    "\n",
    "def cosine(u, v):\n",
    "    return dot(u, v) / (norm(u) * norm(v))\n",
    "\n",
    "\n",
    "def text_too_similar(txt_a, txt_b, threshold=0.9):\n",
    "    ratio = SequenceMatcher(None, txt_a.lower(), txt_b.lower()).ratio()\n",
    "    return ratio > threshold\n",
    "\n",
    "def get_full_description(row):\n",
    "    return f\"{row['subcategory_path']} {row['description']}\".strip()\n",
    "\n",
    "vec_cache = {}\n",
    "def get_vec(text):\n",
    "    if text not in vec_cache:\n",
    "        vec_cache[text] = model.encode(text)\n",
    "    return vec_cache[text]\n",
    "\n",
    "# ==============================\n",
    "print(\"Loading CSV...\")\n",
    "with open(INPUT_CSV, \"r\") as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    rows = [r for r in reader if r.get(\"statement_type\")]\n",
    "    all_rows = rows  # For cross-statement negative sampling\n",
    "\n",
    "by_statement = defaultdict(list)\n",
    "for r in rows:\n",
    "    by_statement[r[\"statement_type\"]].append(r)\n",
    "\n",
    "triplets = []\n",
    "triplet_count = 0\n",
    "triplet_attempts = 0\n",
    "used_combos = set()  # (anchor_tag, pos_tag, neg_tag)\n",
    "\n",
    "\n",
    "def partial_save():\n",
    "    partial_file = \"data/us_gaap_triplet_training_data_partial.jsonl\"\n",
    "    with open(partial_file, \"w\") as pf:\n",
    "        for item in triplets:\n",
    "            pf.write(json.dumps(item) + \"\\n\")\n",
    "    print(f\"[PARTIAL SAVE] Wrote {len(triplets)} triplets to {partial_file}\")\n",
    "\n",
    "# ========== GENERATE TRIPLETS ==========\n",
    "\n",
    "for statement_type, tag_rows in by_statement.items():\n",
    "    random.shuffle(tag_rows)\n",
    "\n",
    "    for anchor_row in tag_rows:\n",
    "        if triplet_count >= MAX_TRIPLETS:\n",
    "            break\n",
    "\n",
    "        anchor_tag = anchor_row[\"tag\"]\n",
    "        anchor_balance = anchor_row.get(\"balance\", \"\")\n",
    "        anchor_period = anchor_row.get(\"period_type\", \"\")\n",
    "        anchor_desc = anchor_row[\"description\"]\n",
    "        anchor_subcategory_path = anchor_row['subcategory_path']\n",
    "        anchor_full_desc = get_full_description(anchor_row)\n",
    "\n",
    "        anchor_vec = get_vec(anchor_full_desc)\n",
    "\n",
    "        # Positive candidates (same statement_type, balance, period, exclude anchor)\n",
    "        positives = [r for r in tag_rows if r[\"balance\"] == anchor_balance and r[\"period_type\"] == anchor_period and r[\"tag\"] != anchor_tag]\n",
    "        if not positives:\n",
    "            continue\n",
    "\n",
    "        positive_sims = []\n",
    "        for candidate in positives:\n",
    "            candidate_vec = get_vec(get_full_description(candidate))\n",
    "            candidate_sim = cosine(candidate_vec, anchor_vec)\n",
    "            positive_sims.append((candidate, candidate_sim))\n",
    "\n",
    "            if candidate_sim >= POSITIVE_SIM_THRESHOLD:\n",
    "                positive_sims.append((candidate, candidate_sim))\n",
    "\n",
    "        # Sort by similarity descending and take top N\n",
    "        positive_candidates = [\n",
    "            c for c, _ in sorted(positive_sims, key=lambda x: x[1], reverse=True)\n",
    "        ][:POSITIVE_ATTEMPTS_PER_ANCHOR]\n",
    "\n",
    "        for p_row in positive_candidates:\n",
    "            if triplet_count >= MAX_TRIPLETS:\n",
    "                break\n",
    "\n",
    "            p_full_desc = get_full_description(p_row)\n",
    "            if text_too_similar(anchor_full_desc, p_full_desc, NEAR_DUPLICATE_ANCHOR_POS_THRESHOLD):\n",
    "                continue\n",
    "\n",
    "            p_vec = get_vec(p_full_desc)\n",
    "            sim_pos = cosine(anchor_vec, p_vec)\n",
    "\n",
    "            use_cross_statement = random.random() < NEGATIVE_CROSS_STATEMENT_RATIO\n",
    "\n",
    "            if use_cross_statement:\n",
    "                negatives = [\n",
    "                    r for r in all_rows\n",
    "                    if r[\"tag\"] not in (anchor_tag, p_row[\"tag\"])\n",
    "                    and r.get(\"statement_type\") != statement_type\n",
    "                    and (\n",
    "                        (anchor_balance and r.get(\"balance\") and r[\"balance\"] != anchor_balance)\n",
    "                        or (anchor_period and r.get(\"period_type\") and r[\"period_type\"] != anchor_period)\n",
    "                    )\n",
    "                ]\n",
    "            else:\n",
    "                negatives = [\n",
    "                    r for r in tag_rows\n",
    "                    if r[\"tag\"] != p_row[\"tag\"]\n",
    "                    and (\n",
    "                        (anchor_balance and r.get(\"balance\") and r[\"balance\"] != anchor_balance)\n",
    "                        or (anchor_period and r.get(\"period_type\") and r[\"period_type\"] != anchor_period)\n",
    "                    )\n",
    "                ]\n",
    "\n",
    "            if not negatives:\n",
    "                continue\n",
    "\n",
    "            negative_sims = []\n",
    "            for candidate in negatives:\n",
    "                candidate_vec = get_vec(get_full_description(candidate))\n",
    "                candidate_sim = cosine(candidate_vec, anchor_vec)\n",
    "                negative_sims.append((candidate, candidate_sim))\n",
    "\n",
    "            # Sort by similarity descending and take bottom N\n",
    "            negative_candidates = [\n",
    "                c for c, _ in sorted(negative_sims, key=lambda x: x[1], reverse=False)\n",
    "            ][:NEGATIVE_ATTEMPTS_PER_POSITIVE]\n",
    "\n",
    "            valid_neg_found = 0\n",
    "            for n_row in negative_candidates:\n",
    "                if triplet_count >= MAX_TRIPLETS:\n",
    "                    break\n",
    "\n",
    "                combo_key = (anchor_tag, p_row[\"tag\"], n_row[\"tag\"])\n",
    "                if combo_key in used_combos:\n",
    "                    continue\n",
    "\n",
    "                n_full_desc = get_full_description(n_row)\n",
    "                n_vec = get_vec(n_full_desc)\n",
    "                sim_neg = cosine(anchor_vec, n_vec)\n",
    "                triplet_attempts += 1\n",
    "\n",
    "                if sim_pos >= sim_neg + MIN_MARGIN:\n",
    "                    # Randomly decide if we add statement type (for the anchor_vec)\n",
    "                    if random.random() < 0.5:\n",
    "                        anchor_text = f\"{statement_type.lower()} {anchor_desc}\"\n",
    "                    else:\n",
    "                        anchor_text = anchor_desc\n",
    "\n",
    "                    triplets.append({\n",
    "                        \"anchor\": anchor_text,\n",
    "                        \"positive\": p_full_desc,\n",
    "                        \"negative\": n_full_desc,\n",
    "                        \"positive_tag\": p_row[\"tag\"],\n",
    "                        \"negative_tag\": n_row[\"tag\"]\n",
    "                    })\n",
    "                    used_combos.add(combo_key)\n",
    "                    triplet_count += 1\n",
    "                    valid_neg_found += 1\n",
    "\n",
    "                    if triplet_count % PARTIAL_SAVE_INTERVAL == 0:\n",
    "                        partial_save()\n",
    "\n",
    "                    if valid_neg_found >= MAX_NEG_MATCHES_PER_POS:\n",
    "                        break\n",
    "\n",
    "# ========== SAVE FINAL ==========\n",
    "with open(OUTPUT_JSONL, \"w\") as out_f:\n",
    "    for row in triplets:\n",
    "        out_f.write(json.dumps(row) + \"\\n\")\n",
    "\n",
    "print(f\"âœ… Saved {len(triplets)} triplets to {OUTPUT_JSONL}\")\n",
    "print(f\"ðŸ§  Total triplet candidates checked: {triplet_attempts}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

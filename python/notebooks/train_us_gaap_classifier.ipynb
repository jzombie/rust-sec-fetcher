{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "import optuna\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.callbacks import Callback\n",
    "from torchmetrics.classification import MulticlassAccuracy\n",
    "\n",
    "# === SEED ===\n",
    "SEED = 42\n",
    "def seed_everything(seed: int):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    pl.seed_everything(seed, workers=True)\n",
    "\n",
    "# Ensure it's called!\n",
    "seed_everything(SEED)\n",
    "\n",
    "# === CONFIG ===\n",
    "DATASET_PATH = \"data/us_gaap_multilabel_training_data.json\"\n",
    "MODEL_NAME = \"BAAI/bge-large-en-v1.5\"\n",
    "OUTPUT_PATH = \"data/fine_tuned_gaap_classifier\"\n",
    "os.makedirs(OUTPUT_PATH, exist_ok=True)\n",
    "OPTUNA_DB_PATH = os.path.join(OUTPUT_PATH, \"optuna_study.db\")\n",
    "EPOCHS = 200\n",
    "PATIENCE = 5\n",
    "VALIDATION_SPLIT = 0.2\n",
    "\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "with open(DATASET_PATH, \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "def label_hash(entry):\n",
    "    return f\"{entry['labels']['statement_type']}_{entry['labels']['balance']}_{entry['labels']['period_type']}\"\n",
    "\n",
    "def get_split():\n",
    "    label_hashes = [label_hash(d) for d in data]\n",
    "    hash_counts = Counter(label_hashes)\n",
    "    common_data, common_labels, rare_data = [], [], []\n",
    "    for i, lh in enumerate(label_hashes):\n",
    "        if hash_counts[lh] >= 2:\n",
    "            common_data.append(data[i])\n",
    "            common_labels.append(lh)\n",
    "        else:\n",
    "            rare_data.append(data[i])\n",
    "    splitter = StratifiedShuffleSplit(n_splits=1, test_size=VALIDATION_SPLIT, random_state=42)\n",
    "    train_idx, val_idx = next(splitter.split(common_data, common_labels))\n",
    "    train_data = [common_data[i] for i in train_idx]\n",
    "    val_data = [common_data[i] for i in val_idx]\n",
    "    train_data.extend(rare_data)\n",
    "    return train_data, val_data\n",
    "\n",
    "class MultiLabelDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.samples = [\n",
    "            (d[\"text\"], torch.tensor([\n",
    "                d[\"labels\"][\"statement_type\"],\n",
    "                d[\"labels\"][\"balance\"],\n",
    "                d[\"labels\"][\"period_type\"]\n",
    "            ], dtype=torch.long))\n",
    "            for d in data\n",
    "        ]\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.samples[idx]\n",
    "\n",
    "def collate_fn(batch):\n",
    "    texts, labels = zip(*batch)\n",
    "    return list(texts), torch.stack(labels)\n",
    "\n",
    "class AttentionLayer(torch.nn.Module):\n",
    "    def __init__(self, input_dim: int, hidden_dim: int = 128):\n",
    "        super().__init__()\n",
    "        self.attn = torch.nn.Sequential(\n",
    "            torch.nn.Linear(input_dim, hidden_dim),\n",
    "            torch.nn.GELU(),\n",
    "            torch.nn.Linear(hidden_dim, 1) # Scalar attention score\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Apply attention over a batch of embeddings.\n",
    "        x: (batch_size, input_dim)\n",
    "        returns: (batch_size, input_dim)\n",
    "        \"\"\"\n",
    "        # Simulate sequence: [batch_size, 1, dim]\n",
    "        x = x.unsqueeze(1)\n",
    "        weights = torch.softmax(self.attn(x), dim=1)  # (batch_size, 1, 1)\n",
    "        attended = torch.sum(weights * x, dim=1)      # (batch_size, dim)\n",
    "        return attended\n",
    "\n",
    "\n",
    "class GAAPClassifier(pl.LightningModule):\n",
    "    def __init__(self, batch_size, lr, weight_decay, model_name, units_st, units_bal, units_pt, dropout_rate):\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.lr = lr\n",
    "        self.weight_decay = weight_decay\n",
    "        self.model_name = model_name\n",
    "        self.encoder = SentenceTransformer(model_name, device=device)\n",
    "        dim = self.encoder.get_sentence_embedding_dimension()\n",
    "\n",
    "        self.attn = AttentionLayer(dim)\n",
    "        self.norm = torch.nn.LayerNorm(dim)\n",
    "\n",
    "        # self.head_st = torch.nn.Linear(dim, 3) # Dependent on number of classes\n",
    "        # self.head_bal = torch.nn.Linear(dim, 3) # Dependent on number of classes\n",
    "        # self.head_pt = torch.nn.Linear(dim, 3) # Dependent on number of classes\n",
    "\n",
    "        self.head_st = torch.nn.Sequential(\n",
    "            torch.nn.Linear(dim, units_st),\n",
    "            torch.nn.GELU(),\n",
    "            torch.nn.Dropout(dropout_rate),\n",
    "            torch.nn.Linear(units_st, 3)  # Dependent on number of classes\n",
    "        )\n",
    "\n",
    "        self.head_bal = torch.nn.Sequential(\n",
    "            torch.nn.Linear(dim, units_bal),\n",
    "            torch.nn.GELU(),\n",
    "            torch.nn.Dropout(dropout_rate),\n",
    "            torch.nn.Linear(units_bal, 3)  # Dependent on number of classes\n",
    "        )\n",
    "\n",
    "        self.head_pt = torch.nn.Sequential(\n",
    "            torch.nn.Linear(dim, units_pt),\n",
    "            torch.nn.GELU(),\n",
    "            torch.nn.Dropout(dropout_rate),\n",
    "            torch.nn.Linear(units_pt, 3)  # Dependent on number of classes\n",
    "        )\n",
    "\n",
    "        self.loss_fn = torch.nn.CrossEntropyLoss()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.acc_st = MulticlassAccuracy(num_classes=3, average='micro')\n",
    "        self.acc_bal = MulticlassAccuracy(num_classes=3, average='micro')\n",
    "        self.acc_pt = MulticlassAccuracy(num_classes=3, average='micro')\n",
    "\n",
    "\n",
    "    def forward(self, texts):\n",
    "        with torch.no_grad():\n",
    "            embeddings = self.encoder.encode(\n",
    "                texts, convert_to_tensor=True, device=device\n",
    "            )\n",
    "\n",
    "        attended = self.attn(embeddings)\n",
    "        attended = self.norm(attended)\n",
    "\n",
    "        out_st = self.head_st(attended)\n",
    "        out_bal = self.head_bal(attended)\n",
    "        out_pt = self.head_pt(attended)\n",
    "\n",
    "        return out_st, out_bal, out_pt\n",
    "\n",
    "    def compute_loss(self, outputs, labels):\n",
    "        out_st, out_bal, out_pt = outputs\n",
    "        loss_0 = self.loss_fn(out_st, labels[:, 0])\n",
    "        loss_1 = self.loss_fn(out_bal, labels[:, 1])\n",
    "        loss_2 = self.loss_fn(out_pt, labels[:, 2])\n",
    "        return loss_0 + loss_1 + loss_2, (loss_0, loss_1, loss_2)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        texts, labels = batch\n",
    "        outputs = self(texts)\n",
    "        loss, (l0, l1, l2) = self.compute_loss(outputs, labels)\n",
    "        self.log(\"train/loss\", loss, prog_bar=True)\n",
    "        self.log(\"train/loss_statement_type\", l0)\n",
    "        self.log(\"train/loss_balance\", l1)\n",
    "        self.log(\"train/loss_period_type\", l2)\n",
    "\n",
    "        pred_st = torch.argmax(outputs[0], dim=1)\n",
    "        pred_bal = torch.argmax(outputs[1], dim=1)\n",
    "        pred_pt = torch.argmax(outputs[2], dim=1)\n",
    "\n",
    "        self.log(\"train/acc_statement_type\", self.acc_st(pred_st, labels[:, 0]))\n",
    "        self.log(\"train/acc_balance\", self.acc_bal(pred_bal, labels[:, 1]))\n",
    "        self.log(\"train/acc_period_type\", self.acc_pt(pred_pt, labels[:, 2]))\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        texts, labels = batch\n",
    "        outputs = self(texts)\n",
    "        loss, (l0, l1, l2) = self.compute_loss(outputs, labels)\n",
    "        self.log(\"val/loss\", loss, prog_bar=True)\n",
    "        self.log(\"val/loss_statement_type\", l0)\n",
    "        self.log(\"val/loss_balance\", l1)\n",
    "        self.log(\"val/loss_period_type\", l2)\n",
    "\n",
    "        pred_st = torch.argmax(outputs[0], dim=1)\n",
    "        pred_bal = torch.argmax(outputs[1], dim=1)\n",
    "        pred_pt = torch.argmax(outputs[2], dim=1)\n",
    "\n",
    "        self.log(\"val/acc_statement_type\", self.acc_st(pred_st, labels[:, 0]))\n",
    "        self.log(\"val/acc_balance\", self.acc_bal(pred_bal, labels[:, 1]))\n",
    "        self.log(\"val/acc_period_type\", self.acc_pt(pred_pt, labels[:, 2]))\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        params = list(self.head_st.parameters()) + \\\n",
    "                 list(self.head_bal.parameters()) + \\\n",
    "                 list(self.head_pt.parameters())\n",
    "        return torch.optim.AdamW(\n",
    "            params,\n",
    "            lr=self.lr,\n",
    "            weight_decay=self.weight_decay\n",
    "        )\n",
    "\n",
    "# class SafePruningCallback(Callback):\n",
    "#     def __init__(self, trial, monitor: str = \"val/loss\", history_window: int = 10):\n",
    "#         super().__init__()\n",
    "#         self.trial = trial\n",
    "#         self.monitor = monitor\n",
    "#         self.history_window = history_window\n",
    "#         self.recent_losses = []\n",
    "\n",
    "#     def on_validation_end(self, trainer, pl_module):\n",
    "#         current = trainer.callback_metrics.get(self.monitor)\n",
    "#         if current is None:\n",
    "#             return\n",
    "\n",
    "#         self.recent_losses.append(current.item())\n",
    "#         if len(self.recent_losses) > self.history_window:\n",
    "#             self.recent_losses.pop(0)\n",
    "\n",
    "#         if (\n",
    "#             trainer.current_epoch >= self.history_window\n",
    "#             and len(self.recent_losses) == self.history_window\n",
    "#         ):\n",
    "#             avg_loss = sum(self.recent_losses) / self.history_window\n",
    "#             self.trial.report(avg_loss, step=trainer.current_epoch)\n",
    "#             if self.trial.should_prune():\n",
    "#                 print(f\"Pruning trial at epoch {trainer.current_epoch} \"\n",
    "#                       f\"with avg val/loss: {avg_loss:.4f}\")\n",
    "#                 raise optuna.TrialPruned()\n",
    "#         else:\n",
    "#             print(f\"Skipping pruning at epoch {trainer.current_epoch}, \"\n",
    "#                   f\"not enough history ({len(self.recent_losses)}/{self.history_window})\")\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 8, 64, step=8)\n",
    "    lr = trial.suggest_float(\"lr\", 1e-6, 1e-2, log=True)\n",
    "    weight_decay = trial.suggest_float(\"weight_decay\", 0.0, 0.1)\n",
    "    units_st = trial.suggest_int(\"units_st\", 8, 128, step=8)\n",
    "    units_bal = trial.suggest_int(\"units_bal\", 8, 128, step=8)\n",
    "    units_pt = trial.suggest_int(\"units_bal\", 8, 128, step=8) \n",
    "    dropout_rate = trial.suggest_float(\"dropout_rate\", 0, 0.5, step=0.1)\n",
    "\n",
    "    train_data, val_data = get_split()\n",
    "    train_loader = DataLoader(MultiLabelDataset(train_data),\n",
    "                              batch_size=batch_size,\n",
    "                              shuffle=True,\n",
    "                              collate_fn=collate_fn)\n",
    "    val_loader = DataLoader(MultiLabelDataset(val_data),\n",
    "                            batch_size=batch_size,\n",
    "                            shuffle=False,\n",
    "                            collate_fn=collate_fn)\n",
    "\n",
    "    model = GAAPClassifier(\n",
    "        batch_size=batch_size,\n",
    "        lr=lr,\n",
    "        weight_decay=weight_decay,\n",
    "        units_st=units_st,\n",
    "        units_bal=units_bal,\n",
    "        units_pt=units_pt,\n",
    "        dropout_rate=dropout_rate,\n",
    "        model_name=MODEL_NAME\n",
    "    )\n",
    "\n",
    "    log_dir = os.path.join(OUTPUT_PATH, f\"trial_{trial.number}\")\n",
    "    logger = TensorBoardLogger(save_dir=log_dir, name=\"logs\")\n",
    "\n",
    "    early_stop = EarlyStopping(monitor=\"val/loss\", patience=PATIENCE, mode=\"min\")\n",
    "    checkpoint_cb = ModelCheckpoint(\n",
    "        dirpath=os.path.join(log_dir, \"checkpoints\"),\n",
    "        filename=\"best\",\n",
    "        monitor=\"val/loss\",\n",
    "        mode=\"min\",\n",
    "        save_top_k=1,\n",
    "        save_weights_only=True\n",
    "    )\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        logger=logger,\n",
    "        max_epochs=EPOCHS,\n",
    "        enable_checkpointing=True,\n",
    "        callbacks=[\n",
    "            early_stop,\n",
    "            checkpoint_cb,\n",
    "            # SafePruningCallback(trial, monitor=\"val/loss\")\n",
    "        ],\n",
    "        log_every_n_steps=1,\n",
    "        accelerator=\"auto\",\n",
    "        devices=1\n",
    "    )\n",
    "\n",
    "    trainer.fit(model, train_dataloaders=train_loader, val_dataloaders=val_loader)\n",
    "    print(\"Best checkpoint:\", checkpoint_cb.best_model_path)\n",
    "    return trainer.callback_metrics[\"val/loss\"].item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-22 20:56:45,583] A new study created in RDB with name: gaap_tuning\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name     | Type                | Params | Mode \n",
      "---------------------------------------------------------\n",
      "0 | encoder  | SentenceTransformer | 335 M  | train\n",
      "1 | attn     | AttentionLayer      | 131 K  | train\n",
      "2 | norm     | LayerNorm           | 2.0 K  | train\n",
      "3 | head_st  | Sequential          | 131 K  | train\n",
      "4 | head_bal | Sequential          | 131 K  | train\n",
      "5 | head_pt  | Sequential          | 131 K  | train\n",
      "6 | loss_fn  | CrossEntropyLoss    | 0      | train\n",
      "7 | acc_st   | MulticlassAccuracy  | 0      | train\n",
      "8 | acc_bal  | MulticlassAccuracy  | 0      | train\n",
      "9 | acc_pt   | MulticlassAccuracy  | 0      | train\n",
      "---------------------------------------------------------\n",
      "335 M     Trainable params\n",
      "0         Non-trainable params\n",
      "335 M     Total params\n",
      "1,342.680 Total estimated model params size (MB)\n",
      "29        Modules in train mode\n",
      "444       Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8228f387cd3744799c0b7dd2601326f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |                                        | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Volumes/2TB Storage Vault/rust-sec-fetcher/python/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=9` in the `DataLoader` to improve performance.\n",
      "/Volumes/2TB Storage Vault/rust-sec-fetcher/python/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=9` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae83283561ed4fa790f1b4db7419226c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                               | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e70ce296ca74304bd459184748b5c30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dae61d2a6822402e8b590031533f4816",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fcca1353b064a848f9c501da879b4b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51ca5b1d83a84a9a9214caf14fcc3e6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "025e8c995e854568a643689dc7f1cb6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d3e95e03d3b4a5eab8506e9dd0d7d81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a0361f5b1ad4da18803ef6c934745e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7624f6fc2f9741759c798cb08de660cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b885de7a737478696d5b35256401090",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a15eb3e7c674009893c28b67adc4186",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fe7123026b64ec2a9f5ccd16c6ec69b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "480db759935f40f98d081b4f83a95c28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1542e544fae94e59baf7705f476e992b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10ddf37da71b4dd887b3666d11f68c1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "842acd2cc8c746588b51a9e816ac5988",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-22 21:00:34,595] Trial 0 finished with value: 0.847109854221344 and parameters: {'batch_size': 48, 'lr': 0.000722000755763429, 'weight_decay': 0.09144624512486152, 'units_st': 128, 'units_bal': 128, 'dropout_rate': 0.1}. Best is trial 0 with value: 0.847109854221344.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best checkpoint: /Volumes/2TB Storage Vault/rust-sec-fetcher/python/data/fine_tuned_gaap_classifier/trial_0/checkpoints/best.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name     | Type                | Params | Mode \n",
      "---------------------------------------------------------\n",
      "0 | encoder  | SentenceTransformer | 335 M  | train\n",
      "1 | attn     | AttentionLayer      | 131 K  | train\n",
      "2 | norm     | LayerNorm           | 2.0 K  | train\n",
      "3 | head_st  | Sequential          | 115 K  | train\n",
      "4 | head_bal | Sequential          | 106 K  | train\n",
      "5 | head_pt  | Sequential          | 106 K  | train\n",
      "6 | loss_fn  | CrossEntropyLoss    | 0      | train\n",
      "7 | acc_st   | MulticlassAccuracy  | 0      | train\n",
      "8 | acc_bal  | MulticlassAccuracy  | 0      | train\n",
      "9 | acc_pt   | MulticlassAccuracy  | 0      | train\n",
      "---------------------------------------------------------\n",
      "335 M     Trainable params\n",
      "0         Non-trainable params\n",
      "335 M     Total params\n",
      "1,342.417 Total estimated model params size (MB)\n",
      "29        Modules in train mode\n",
      "444       Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e37f2d7251143b0830c847a29fda126",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |                                        | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Volumes/2TB Storage Vault/rust-sec-fetcher/python/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=9` in the `DataLoader` to improve performance.\n",
      "/Volumes/2TB Storage Vault/rust-sec-fetcher/python/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=9` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b88e9cdf2ab8456cb3b9214dc678d453",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                               | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcb6d1ebb75f4aeaa75da6e81de98809",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a87e5f1263349b684a9ed14a289d075",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85e23e48e9c6413eb97f3a3bed474419",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cced70ca54d4d26bc0aaafc55f2d150",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07b34bc9b80f434c809897fb24696d7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c164a537d9943abb6c76bda7f1cde94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "289ce04e3d1f4aeebfd0835f979a1812",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92f5ec0ffc11474893afed7abae10fbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91e0cbd97725455eb860e8cc3fcdd1d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66c1a2518775411fac9a28b9c241f560",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "333dcc38236b4a8c8fdec08aaa620795",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed6791b7486d4744850ec1863653b529",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e8f03c69c274aa48b0b13883a238342",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88d853565fd64226b0afc46c0623afd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f38a73d75e7b49eb9a2e78e99ec473b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1677b0146e147589127459dfe47e214",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f633227a8ff3409a9a97d871bc84e506",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab7db84db7814a3c92bf77b23e8e51b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Detected KeyboardInterrupt, attempting graceful shutdown ...\n",
      "[W 2025-03-22 21:10:02,060] Trial 1 failed with parameters: {'batch_size': 8, 'lr': 0.005796186821065959, 'weight_decay': 0.06349790279915665, 'units_st': 112, 'units_bal': 104, 'dropout_rate': 0.30000000000000004} because of the following error: NameError(\"name 'exit' is not defined\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/Volumes/2TB Storage Vault/rust-sec-fetcher/python/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py\", line 48, in _call_and_handle_interrupt\n",
      "    return trainer_fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Volumes/2TB Storage Vault/rust-sec-fetcher/python/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py\", line 599, in _fit_impl\n",
      "    self._run(model, ckpt_path=ckpt_path)\n",
      "  File \"/Volumes/2TB Storage Vault/rust-sec-fetcher/python/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py\", line 1012, in _run\n",
      "    results = self._run_stage()\n",
      "              ^^^^^^^^^^^^^^^^^\n",
      "  File \"/Volumes/2TB Storage Vault/rust-sec-fetcher/python/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py\", line 1056, in _run_stage\n",
      "    self.fit_loop.run()\n",
      "  File \"/Volumes/2TB Storage Vault/rust-sec-fetcher/python/venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py\", line 216, in run\n",
      "    self.advance()\n",
      "  File \"/Volumes/2TB Storage Vault/rust-sec-fetcher/python/venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py\", line 455, in advance\n",
      "    self.epoch_loop.run(self._data_fetcher)\n",
      "  File \"/Volumes/2TB Storage Vault/rust-sec-fetcher/python/venv/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py\", line 151, in run\n",
      "    self.on_advance_end(data_fetcher)\n",
      "  File \"/Volumes/2TB Storage Vault/rust-sec-fetcher/python/venv/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py\", line 370, in on_advance_end\n",
      "    self.val_loop.run()\n",
      "  File \"/Volumes/2TB Storage Vault/rust-sec-fetcher/python/venv/lib/python3.12/site-packages/pytorch_lightning/loops/utilities.py\", line 179, in _decorator\n",
      "    return loop_run(self, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Volumes/2TB Storage Vault/rust-sec-fetcher/python/venv/lib/python3.12/site-packages/pytorch_lightning/loops/evaluation_loop.py\", line 145, in run\n",
      "    self._evaluation_step(batch, batch_idx, dataloader_idx, dataloader_iter)\n",
      "  File \"/Volumes/2TB Storage Vault/rust-sec-fetcher/python/venv/lib/python3.12/site-packages/pytorch_lightning/loops/evaluation_loop.py\", line 437, in _evaluation_step\n",
      "    output = call._call_strategy_hook(trainer, hook_name, *step_args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Volumes/2TB Storage Vault/rust-sec-fetcher/python/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py\", line 328, in _call_strategy_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Volumes/2TB Storage Vault/rust-sec-fetcher/python/venv/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py\", line 412, in validation_step\n",
      "    return self.lightning_module.validation_step(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/hn/cb9fbnv50kqdqz8zh4yth8p40000gn/T/ipykernel_14612/1592372811.py\", line 195, in validation_step\n",
      "    outputs = self(texts)\n",
      "              ^^^^^^^^^^^\n",
      "  File \"/Volumes/2TB Storage Vault/rust-sec-fetcher/python/venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Volumes/2TB Storage Vault/rust-sec-fetcher/python/venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/hn/cb9fbnv50kqdqz8zh4yth8p40000gn/T/ipykernel_14612/1592372811.py\", line 154, in forward\n",
      "    embeddings = self.encoder.encode(\n",
      "                 ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Volumes/2TB Storage Vault/rust-sec-fetcher/python/venv/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py\", line 583, in encode\n",
      "    self.to(device)\n",
      "  File \"/Volumes/2TB Storage Vault/rust-sec-fetcher/python/venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1343, in to\n",
      "    return self._apply(convert)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Volumes/2TB Storage Vault/rust-sec-fetcher/python/venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 903, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/Volumes/2TB Storage Vault/rust-sec-fetcher/python/venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 903, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/Volumes/2TB Storage Vault/rust-sec-fetcher/python/venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 903, in _apply\n",
      "    module._apply(fn)\n",
      "  [Previous line repeated 4 more times]\n",
      "  File \"/Volumes/2TB Storage Vault/rust-sec-fetcher/python/venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 935, in _apply\n",
      "    should_use_swap_tensors or is_traceable_wrapper_subclass(param_applied)\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Volumes/2TB Storage Vault/rust-sec-fetcher/python/venv/lib/python3.12/site-packages/torch/utils/_python_dispatch.py\", line 401, in is_traceable_wrapper_subclass\n",
      "    and hasattr(t, \"__tensor_flatten__\")\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Volumes/2TB Storage Vault/rust-sec-fetcher/python/venv/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/var/folders/hn/cb9fbnv50kqdqz8zh4yth8p40000gn/T/ipykernel_14612/1592372811.py\", line 310, in objective\n",
      "    trainer.fit(model, train_dataloaders=train_loader, val_dataloaders=val_loader)\n",
      "  File \"/Volumes/2TB Storage Vault/rust-sec-fetcher/python/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py\", line 561, in fit\n",
      "    call._call_and_handle_interrupt(\n",
      "  File \"/Volumes/2TB Storage Vault/rust-sec-fetcher/python/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py\", line 65, in _call_and_handle_interrupt\n",
      "    exit(1)\n",
      "    ^^^^\n",
      "NameError: name 'exit' is not defined\n",
      "[W 2025-03-22 21:10:02,071] Trial 1 failed with value None.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'exit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/Volumes/2TB Storage Vault/rust-sec-fetcher/python/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py:48\u001b[39m, in \u001b[36m_call_and_handle_interrupt\u001b[39m\u001b[34m(trainer, trainer_fn, *args, **kwargs)\u001b[39m\n\u001b[32m     47\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Volumes/2TB Storage Vault/rust-sec-fetcher/python/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py:599\u001b[39m, in \u001b[36mTrainer._fit_impl\u001b[39m\u001b[34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[39m\n\u001b[32m    593\u001b[39m ckpt_path = \u001b[38;5;28mself\u001b[39m._checkpoint_connector._select_ckpt_path(\n\u001b[32m    594\u001b[39m     \u001b[38;5;28mself\u001b[39m.state.fn,\n\u001b[32m    595\u001b[39m     ckpt_path,\n\u001b[32m    596\u001b[39m     model_provided=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    597\u001b[39m     model_connected=\u001b[38;5;28mself\u001b[39m.lightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    598\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m599\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    601\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.state.stopped\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Volumes/2TB Storage Vault/rust-sec-fetcher/python/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py:1012\u001b[39m, in \u001b[36mTrainer._run\u001b[39m\u001b[34m(self, model, ckpt_path)\u001b[39m\n\u001b[32m   1009\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m   1010\u001b[39m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[32m   1011\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1012\u001b[39m results = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1014\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m   1015\u001b[39m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[32m   1016\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Volumes/2TB Storage Vault/rust-sec-fetcher/python/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py:1056\u001b[39m, in \u001b[36mTrainer._run_stage\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1055\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.autograd.set_detect_anomaly(\u001b[38;5;28mself\u001b[39m._detect_anomaly):\n\u001b[32m-> \u001b[39m\u001b[32m1056\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfit_loop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1057\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Volumes/2TB Storage Vault/rust-sec-fetcher/python/venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:216\u001b[39m, in \u001b[36m_FitLoop.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    215\u001b[39m \u001b[38;5;28mself\u001b[39m.on_advance_start()\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[38;5;28mself\u001b[39m.on_advance_end()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Volumes/2TB Storage Vault/rust-sec-fetcher/python/venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:455\u001b[39m, in \u001b[36m_FitLoop.advance\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    454\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m._data_fetcher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m455\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mepoch_loop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_data_fetcher\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Volumes/2TB Storage Vault/rust-sec-fetcher/python/venv/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py:151\u001b[39m, in \u001b[36m_TrainingEpochLoop.run\u001b[39m\u001b[34m(self, data_fetcher)\u001b[39m\n\u001b[32m    150\u001b[39m     \u001b[38;5;28mself\u001b[39m.advance(data_fetcher)\n\u001b[32m--> \u001b[39m\u001b[32m151\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mon_advance_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_fetcher\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    152\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Volumes/2TB Storage Vault/rust-sec-fetcher/python/venv/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py:370\u001b[39m, in \u001b[36m_TrainingEpochLoop.on_advance_end\u001b[39m\u001b[34m(self, data_fetcher)\u001b[39m\n\u001b[32m    368\u001b[39m     call._call_lightning_module_hook(\u001b[38;5;28mself\u001b[39m.trainer, \u001b[33m\"\u001b[39m\u001b[33mon_validation_model_zero_grad\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m370\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mval_loop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    371\u001b[39m \u001b[38;5;28mself\u001b[39m.trainer.training = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Volumes/2TB Storage Vault/rust-sec-fetcher/python/venv/lib/python3.12/site-packages/pytorch_lightning/loops/utilities.py:179\u001b[39m, in \u001b[36m_no_grad_context.<locals>._decorator\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    178\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m context_manager():\n\u001b[32m--> \u001b[39m\u001b[32m179\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloop_run\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Volumes/2TB Storage Vault/rust-sec-fetcher/python/venv/lib/python3.12/site-packages/pytorch_lightning/loops/evaluation_loop.py:145\u001b[39m, in \u001b[36m_EvaluationLoop.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    144\u001b[39m     \u001b[38;5;66;03m# run step hooks\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m145\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_evaluation_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    146\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[32m    147\u001b[39m     \u001b[38;5;66;03m# this needs to wrap the `*_step` call too (not just `next`) for `dataloader_iter` support\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Volumes/2TB Storage Vault/rust-sec-fetcher/python/venv/lib/python3.12/site-packages/pytorch_lightning/loops/evaluation_loop.py:437\u001b[39m, in \u001b[36m_EvaluationLoop._evaluation_step\u001b[39m\u001b[34m(self, batch, batch_idx, dataloader_idx, dataloader_iter)\u001b[39m\n\u001b[32m    432\u001b[39m step_args = (\n\u001b[32m    433\u001b[39m     \u001b[38;5;28mself\u001b[39m._build_step_args_from_hook_kwargs(hook_kwargs, hook_name)\n\u001b[32m    434\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m using_dataloader_iter\n\u001b[32m    435\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m (dataloader_iter,)\n\u001b[32m    436\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m437\u001b[39m output = \u001b[43mcall\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_strategy_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhook_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mstep_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    439\u001b[39m \u001b[38;5;28mself\u001b[39m.batch_progress.increment_processed()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Volumes/2TB Storage Vault/rust-sec-fetcher/python/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py:328\u001b[39m, in \u001b[36m_call_strategy_hook\u001b[39m\u001b[34m(trainer, hook_name, *args, **kwargs)\u001b[39m\n\u001b[32m    327\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m trainer.profiler.profile(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[Strategy]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrainer.strategy.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m328\u001b[39m     output = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    330\u001b[39m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Volumes/2TB Storage Vault/rust-sec-fetcher/python/venv/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py:412\u001b[39m, in \u001b[36mStrategy.validation_step\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    411\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_redirection(\u001b[38;5;28mself\u001b[39m.model, \u001b[38;5;28mself\u001b[39m.lightning_module, \u001b[33m\"\u001b[39m\u001b[33mvalidation_step\u001b[39m\u001b[33m\"\u001b[39m, *args, **kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m412\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlightning_module\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalidation_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 195\u001b[39m, in \u001b[36mGAAPClassifier.validation_step\u001b[39m\u001b[34m(self, batch, batch_idx)\u001b[39m\n\u001b[32m    194\u001b[39m texts, labels = batch\n\u001b[32m--> \u001b[39m\u001b[32m195\u001b[39m outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    196\u001b[39m loss, (l0, l1, l2) = \u001b[38;5;28mself\u001b[39m.compute_loss(outputs, labels)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Volumes/2TB Storage Vault/rust-sec-fetcher/python/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Volumes/2TB Storage Vault/rust-sec-fetcher/python/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 154\u001b[39m, in \u001b[36mGAAPClassifier.forward\u001b[39m\u001b[34m(self, texts)\u001b[39m\n\u001b[32m    153\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m--> \u001b[39m\u001b[32m154\u001b[39m     embeddings = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    155\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\n\u001b[32m    156\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    158\u001b[39m attended = \u001b[38;5;28mself\u001b[39m.attn(embeddings)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Volumes/2TB Storage Vault/rust-sec-fetcher/python/venv/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py:583\u001b[39m, in \u001b[36mSentenceTransformer.encode\u001b[39m\u001b[34m(self, sentences, prompt_name, prompt, batch_size, show_progress_bar, output_value, precision, convert_to_numpy, convert_to_tensor, device, normalize_embeddings, **kwargs)\u001b[39m\n\u001b[32m    581\u001b[39m     device = \u001b[38;5;28mself\u001b[39m.device\n\u001b[32m--> \u001b[39m\u001b[32m583\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    585\u001b[39m all_embeddings = []\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Volumes/2TB Storage Vault/rust-sec-fetcher/python/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1343\u001b[39m, in \u001b[36mModule.to\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1341\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1343\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Volumes/2TB Storage Vault/rust-sec-fetcher/python/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:903\u001b[39m, in \u001b[36mModule._apply\u001b[39m\u001b[34m(self, fn, recurse)\u001b[39m\n\u001b[32m    902\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.children():\n\u001b[32m--> \u001b[39m\u001b[32m903\u001b[39m         \u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    905\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Volumes/2TB Storage Vault/rust-sec-fetcher/python/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:903\u001b[39m, in \u001b[36mModule._apply\u001b[39m\u001b[34m(self, fn, recurse)\u001b[39m\n\u001b[32m    902\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.children():\n\u001b[32m--> \u001b[39m\u001b[32m903\u001b[39m         \u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    905\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n",
      "    \u001b[31m[... skipping similar frames: Module._apply at line 903 (4 times)]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Volumes/2TB Storage Vault/rust-sec-fetcher/python/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:903\u001b[39m, in \u001b[36mModule._apply\u001b[39m\u001b[34m(self, fn, recurse)\u001b[39m\n\u001b[32m    902\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.children():\n\u001b[32m--> \u001b[39m\u001b[32m903\u001b[39m         \u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    905\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Volumes/2TB Storage Vault/rust-sec-fetcher/python/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:935\u001b[39m, in \u001b[36mModule._apply\u001b[39m\u001b[34m(self, fn, recurse)\u001b[39m\n\u001b[32m    933\u001b[39m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n\u001b[32m    934\u001b[39m p_should_use_swap_tensors = (\n\u001b[32m--> \u001b[39m\u001b[32m935\u001b[39m     should_use_swap_tensors \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mis_traceable_wrapper_subclass\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam_applied\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    936\u001b[39m )\n\u001b[32m    938\u001b[39m param_grad = param.grad\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Volumes/2TB Storage Vault/rust-sec-fetcher/python/venv/lib/python3.12/site-packages/torch/utils/_python_dispatch.py:401\u001b[39m, in \u001b[36mis_traceable_wrapper_subclass\u001b[39m\u001b[34m(t)\u001b[39m\n\u001b[32m    398\u001b[39m is_subclass = \u001b[38;5;28misinstance\u001b[39m(t, torch.Tensor) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(t) != torch.Tensor\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[32m    400\u001b[39m     is_subclass\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28;43mhasattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m__tensor_flatten__\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    402\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(t, \u001b[33m\"\u001b[39m\u001b[33m__tensor_unflatten__\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    403\u001b[39m )\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01moptuna\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msamplers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TPESampler\n\u001b[32m      4\u001b[39m study = optuna.create_study(\n\u001b[32m      5\u001b[39m      direction=\u001b[33m\"\u001b[39m\u001b[33mminimize\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      6\u001b[39m      sampler=TPESampler(),\n\u001b[32m   (...)\u001b[39m\u001b[32m     14\u001b[39m     )\n\u001b[32m     15\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m \u001b[43mstudy\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m200\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mBest params:\u001b[39m\u001b[33m\"\u001b[39m, study.best_params)\n\u001b[32m     19\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mBest trial:\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Volumes/2TB Storage Vault/rust-sec-fetcher/python/venv/lib/python3.12/site-packages/optuna/study/study.py:475\u001b[39m, in \u001b[36mStudy.optimize\u001b[39m\u001b[34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m    373\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34moptimize\u001b[39m(\n\u001b[32m    374\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    375\u001b[39m     func: ObjectiveFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m    382\u001b[39m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    383\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    384\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[32m    385\u001b[39m \n\u001b[32m    386\u001b[39m \u001b[33;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    473\u001b[39m \u001b[33;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[32m    474\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m475\u001b[39m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    476\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    477\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    478\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    479\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    480\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    481\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    482\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    483\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    484\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    485\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Volumes/2TB Storage Vault/rust-sec-fetcher/python/venv/lib/python3.12/site-packages/optuna/study/_optimize.py:63\u001b[39m, in \u001b[36m_optimize\u001b[39m\u001b[34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m     61\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     62\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs == \u001b[32m1\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     64\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     76\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs == -\u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Volumes/2TB Storage Vault/rust-sec-fetcher/python/venv/lib/python3.12/site-packages/optuna/study/_optimize.py:160\u001b[39m, in \u001b[36m_optimize_sequential\u001b[39m\u001b[34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[39m\n\u001b[32m    157\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    159\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m160\u001b[39m     frozen_trial = \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    162\u001b[39m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[32m    163\u001b[39m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[32m    164\u001b[39m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[32m    165\u001b[39m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[32m    166\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Volumes/2TB Storage Vault/rust-sec-fetcher/python/venv/lib/python3.12/site-packages/optuna/study/_optimize.py:248\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    241\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mShould not reach.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    243\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    244\u001b[39m     frozen_trial.state == TrialState.FAIL\n\u001b[32m    245\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    246\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[32m    247\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m248\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Volumes/2TB Storage Vault/rust-sec-fetcher/python/venv/lib/python3.12/site-packages/optuna/study/_optimize.py:197\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    195\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial._trial_id, study._storage):\n\u001b[32m    196\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m197\u001b[39m         value_or_values = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    198\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions.TrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    199\u001b[39m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[32m    200\u001b[39m         state = TrialState.PRUNED\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 310\u001b[39m, in \u001b[36mobjective\u001b[39m\u001b[34m(trial)\u001b[39m\n\u001b[32m    287\u001b[39m checkpoint_cb = ModelCheckpoint(\n\u001b[32m    288\u001b[39m     dirpath=os.path.join(log_dir, \u001b[33m\"\u001b[39m\u001b[33mcheckpoints\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m    289\u001b[39m     filename=\u001b[33m\"\u001b[39m\u001b[33mbest\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    293\u001b[39m     save_weights_only=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    294\u001b[39m )\n\u001b[32m    296\u001b[39m trainer = pl.Trainer(\n\u001b[32m    297\u001b[39m     logger=logger,\n\u001b[32m    298\u001b[39m     max_epochs=EPOCHS,\n\u001b[32m   (...)\u001b[39m\u001b[32m    307\u001b[39m     devices=\u001b[32m1\u001b[39m\n\u001b[32m    308\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m310\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    311\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mBest checkpoint:\u001b[39m\u001b[33m\"\u001b[39m, checkpoint_cb.best_model_path)\n\u001b[32m    312\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m trainer.callback_metrics[\u001b[33m\"\u001b[39m\u001b[33mval/loss\u001b[39m\u001b[33m\"\u001b[39m].item()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Volumes/2TB Storage Vault/rust-sec-fetcher/python/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py:561\u001b[39m, in \u001b[36mTrainer.fit\u001b[39m\u001b[34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[39m\n\u001b[32m    559\u001b[39m \u001b[38;5;28mself\u001b[39m.training = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    560\u001b[39m \u001b[38;5;28mself\u001b[39m.should_stop = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m561\u001b[39m \u001b[43mcall\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    562\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[32m    563\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Volumes/2TB Storage Vault/rust-sec-fetcher/python/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py:65\u001b[39m, in \u001b[36m_call_and_handle_interrupt\u001b[39m\u001b[34m(trainer, trainer_fn, *args, **kwargs)\u001b[39m\n\u001b[32m     63\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(launcher, _SubprocessScriptLauncher):\n\u001b[32m     64\u001b[39m         launcher.kill(_get_sigkill_signal())\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m     \u001b[43mexit\u001b[49m(\u001b[32m1\u001b[39m)\n\u001b[32m     67\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exception:\n\u001b[32m     68\u001b[39m     _interrupt(trainer, exception)\n",
      "\u001b[31mNameError\u001b[39m: name 'exit' is not defined"
     ]
    }
   ],
   "source": [
    "from optuna.pruners import HyperbandPruner\n",
    "from optuna.samplers import TPESampler\n",
    "\n",
    "study = optuna.create_study(\n",
    "     direction=\"minimize\",\n",
    "     sampler=TPESampler(),\n",
    "     study_name=\"gaap_tuning\",\n",
    "     storage=f\"sqlite:///{OPTUNA_DB_PATH}\",\n",
    "     load_if_exists=True,\n",
    "     pruner=HyperbandPruner(\n",
    "        min_resource=5,    # usually epochs\n",
    "        max_resource=EPOCHS,  # total epochs\n",
    "        reduction_factor=3\n",
    "    )\n",
    ")\n",
    "study.optimize(objective, n_trials=200)\n",
    "print(\"Best params:\", study.best_params)\n",
    "\n",
    "print(\"Best trial:\")\n",
    "best_trial = study.best_trial\n",
    "print(\"  Value: %.6f\" % best_trial.value)\n",
    "print(\"  Params:\")\n",
    "for k, v in best_trial.params.items():\n",
    "    print(\"    %s: %s\" % (k, v))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

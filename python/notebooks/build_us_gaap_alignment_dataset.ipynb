{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# This snippet ensures consistent import paths across environments.\n",
    "# When running notebooks via JupyterLab's web UI, the current working\n",
    "# directory is often different (e.g., /notebooks) compared to VS Code,\n",
    "# which typically starts at the project root. This handles that by \n",
    "# retrying the import after changing to the parent directory.\n",
    "# \n",
    "# Include this at the top of every notebook to standardize imports\n",
    "# across development environments.\n",
    "\n",
    "try:\n",
    "    from utils.os import chdir_to_git_root\n",
    "except ModuleNotFoundError:\n",
    "    os.chdir(Path.cwd().parent)\n",
    "    print(f\"Retrying import from: {os.getcwd()}\")\n",
    "    from utils.os import chdir_to_git_root\n",
    "\n",
    "chdir_to_git_root(\"python\")\n",
    "\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.pytorch.us_gaap_alignment import build_us_gaap_alignment_dataset\n",
    "from utils.pytorch import seed_everything, get_device\n",
    "\n",
    "device = get_device()\n",
    "\n",
    "output_file = \"data/us_gaap_concepts_with_variations_and_embeddings.jsonl\"\n",
    "\n",
    "build_us_gaap_alignment_dataset(output_file, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Analysis (no alignment model)\n",
    "\n",
    "Result: ~65% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from db import DB\n",
    "from utils import generate_us_gaap_description\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from tqdm import tqdm\n",
    "from utils.pytorch import seed_everything, get_device\n",
    "\n",
    "# Setup for BGE model\n",
    "MODEL_NAME = \"BAAI/bge-large-en-v1.5\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "encoder = AutoModel.from_pretrained(MODEL_NAME)\n",
    "\n",
    "device = get_device()\n",
    "encoder = encoder.to(device)\n",
    "\n",
    "# Database setup\n",
    "db = DB()\n",
    "\n",
    "queries = {\n",
    "    \"concept_variations\": \"\"\"\n",
    "        SELECT\n",
    "            v.text AS input_text,\n",
    "            t.name AS us_gaap_description\n",
    "        FROM us_gaap_concept_description_variation v\n",
    "        JOIN us_gaap_concept t ON t.id = v.us_gaap_concept_id\n",
    "    \"\"\"\n",
    "}\n",
    "\n",
    "# Cache embeddings for each text individually\n",
    "embedding_cache = {}\n",
    "\n",
    "# Generate embeddings for text using the BGE model\n",
    "def generate_embeddings(texts):\n",
    "    \"\"\"\n",
    "    This function generates embeddings for a given list of text descriptions.\n",
    "    It uses the BGE model to generate the embeddings, specifically the [CLS] token representation.\n",
    "    \"\"\"\n",
    "    embeddings = []\n",
    "    for text in texts:\n",
    "        if text in embedding_cache:  # Check if the embedding is cached\n",
    "            embeddings.append(embedding_cache[text])  # Use the cached embedding\n",
    "        else:\n",
    "            # If not cached, generate and cache the embedding\n",
    "            if isinstance(text, str):\n",
    "                texts = [text]  # Convert single string to a list of strings\n",
    "            elif not isinstance(texts, list):\n",
    "                raise ValueError(\"Input must be a string or a list of strings.\")\n",
    "\n",
    "            texts = [str(text) if not isinstance(text, str) else text for text in texts]\n",
    "            inputs = tokenizer(texts, return_tensors='pt', padding=True, truncation=True, max_length=512).to(device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                outputs = encoder(**inputs)\n",
    "            \n",
    "            text_embedding = outputs.last_hidden_state[:, 0, :]  # Use [CLS] token embedding\n",
    "            embedding_cache[text] = text_embedding  # Cache the generated embedding\n",
    "            embeddings.append(text_embedding)\n",
    "    return torch.stack(embeddings)\n",
    "\n",
    "# Function to find the most similar us_gaap_description to a given variation (input text)\n",
    "def find_closest_description(variation, descriptions):\n",
    "    variation_embedding = generate_embeddings([variation]).squeeze(0)  # Remove extra dimensions\n",
    "    \n",
    "    # Generate embeddings for all us_gaap_descriptions\n",
    "    description_embeddings = generate_embeddings(descriptions).squeeze(1)  # Remove extra dimensions\n",
    "\n",
    "    # Compute cosine similarity\n",
    "    similarity = cosine_similarity(variation_embedding.cpu().numpy(), description_embeddings.cpu().numpy())\n",
    "    \n",
    "    # Find the index of the description with the highest cosine similarity\n",
    "    closest_idx = similarity.argmax()\n",
    "    \n",
    "    return descriptions[closest_idx], similarity[0][closest_idx]\n",
    "\n",
    "def build_dataset(query: str):\n",
    "    df = db.get(query, [\"input_text\", \"us_gaap_description\"])\n",
    "\n",
    "    # Apply the generate_us_gaap_description function to the us_gaap_description\n",
    "    df[\"us_gaap_description\"] = df[\"us_gaap_description\"].apply(generate_us_gaap_description)\n",
    "\n",
    "    # For each variation in the dataset, find the closest match to the us_gaap_description\n",
    "    closest_matches = []\n",
    "    is_correct_matches = []\n",
    "    similarities = []\n",
    "    \n",
    "    for _, row in tqdm(df.iterrows(), total=len(df), desc=\"Processing data\"):\n",
    "        # Find the closest us_gaap_description for the current variation\n",
    "        closest_match, similarity = find_closest_description(row[\"input_text\"], df[\"us_gaap_description\"].tolist())\n",
    "        closest_matches.append(closest_match)\n",
    "        similarities.append(similarity)\n",
    "        \n",
    "        # Check if the closest match is the same as the original us_gaap_description\n",
    "        is_correct = closest_match == row[\"us_gaap_description\"]\n",
    "        is_correct_matches.append(is_correct)\n",
    "\n",
    "    # Add the closest match and correctness flag to the dataframe\n",
    "    df[\"closest_match\"] = closest_matches\n",
    "    df[\"similarity\"] = similarities\n",
    "    df[\"is_correct_match\"] = is_correct_matches\n",
    "\n",
    "    # Calculate error rate (percentage of incorrect matches)\n",
    "    total_entries = len(df)\n",
    "    correct_matches = sum(is_correct_matches)\n",
    "    accuracy = correct_matches / total_entries\n",
    "    error_rate = 1 - accuracy\n",
    "    \n",
    "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "    print(f\"Error Rate: {error_rate * 100:.2f}%\")\n",
    "    \n",
    "    # Save as JSONL\n",
    "    df.to_json(f\"data/matched_tags.jsonl\", orient=\"records\", lines=True)\n",
    "    print(f\"Matched data saved to 'matched_tags.jsonl' with {len(df)} rows.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    build_dataset(queries[\"concept_variations\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
